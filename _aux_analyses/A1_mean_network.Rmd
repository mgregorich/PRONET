---
title: 'Auxilliary analysis: Mean network'
author: "Mariella Gregorich"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    css: "css_style.css"
    theme: cosmo
    number_sections: true
    keep_md: no
    fig_caption: true
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: 
      collapsed: true
      smooth_scroll: true
    highlight: tango
bibliography: ..\\references.bib 
---



```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = F, warning=F, message=F)
pacman::p_load(mvtnorm, igraph, NetworkToolbox, Rcpp, RcppEigen, MASS, lqmm, ggplot2, gridExtra,
               stringr, future.apply, parallel, dplyr, tidyr, knitr, reshape2,kableExtra,
               rmarkdown, bookdown, forcats, rmdformats)
set.seed(1234)
source("../x_functions.R")
source("../x_setup.R")
source("../01_data_generation.R")

```

# Background

## Data-generating design
Individual-specific networks are constructed based on the principle that partial correlations between random variables can be obtained through the inversion of the covariance matrix (precision matrix) and taking the ratio of appropriate entries from the precision matrix. It follow the study by @xie2020identifying.

Each individual-specific precision matrix $\Omega_i(r,s)$ is currently constructed based on a transformed $p\times p$-dimensional scale-free mean-structered matrix $\alpha_0$, where $p$ denotes the number of nodes. The mean-structured matrix indicates the default connections between pairs of nodes and is thus the same for all individuals $i=1,..,n$. 

The mean-structure is derived from the Barabasi-Albert model, a stochastic algorithm for scale-free network construction, such that a matrix is obtained with binary entries indicating the presence of a connection with 1 and the absence with 0. The entries of $\alpha_0$ corresponding tHE  presence of a connection are $\alpha_0(r,s)\sim N(0,1) , r, s=1,...,p$. The individual variability is introduced by two individual-specific latent variables $(X_{1i},X_{2i})$ and two $p \times p$-dimensional weight matrices $\alpha_1$ and $\alpha_2$ representing the edge-specific effect of the latent variables on the default structure.

Individual-specific entries $\alpha_i(r,s)$ for each node pair $(r,s)$ are then obtained by
\begin{equation}
\tag{1}
A_i(r,s) = \alpha_0(r,s) + \alpha_1(r,s)X_{1i} + \alpha_2(r,s)X_{2i}, 
\end{equation}
where $\alpha_1$ and $\alpha_2$ are drawn from a uniform distribution $U(0,1)$. The final precision matrix $\Omega_i(r,s)$ is obtained by a transformation $f(.)$, which transforms $A_i\rightarrow (0,1)$ into a beta distribution $Beta(a,b)$ with predefined scaling factors $a$ and $b$.

The partial correlation between node $s$ and $r$ defining the pairwise edge weight for individual $i$ is then constructed through the definition of partial correlation:
\begin{equation}
\tag{2}
w_i(r,s):=\rho_i(s,r)=-\frac{\Omega_i(s,r)}{\sqrt(\Omega_i(s,s)\Omega_i(r,r))}
\end{equation}
The diagonal elements of $\Omega_i$ are set to 1 in $\Omega_i$ such that $\rho_i(r,s) \in [0,1]$.

```{r}
## ----------- Parameters -------------------------

df.sparams <- data.frame("Terms"=c("Sample size", "Nodes",  "Possible edges","Latent processes","Density of the mean network"),
                         "Values"=c(n,p,po,q,round_0(sum(omega.imat!=0)/po*100,2)))
df.sparams  %>%
  kbl(caption="Parameters for the data-generating mechanism", escape = F) %>%
  kable_classic(full_width = T, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```

```{r}
BAdens <- round(edge_density(BA.graph)*100,1)
plot(BA.graph, main=paste0("Visualization of the Barabasi-Alpbert graph (density=", BAdens,"%)"))
```

## Thresholding


In the following we will differentiate between sparsification and thresholding as follows: 
Sparsification will describe the methodology to reduce the network density either by a

* weight-based approach
* density-based approach
while thresholding describes the methodology of how retained edge weights are transformed either by

* Weight trimming
\begin{equation}
    \tilde{w}_{rs}=
    \begin{cases}
      w_{rs}, & \text{if}\ w_{rs} > \tau \\
      0, & \text{otherwise}
    \end{cases}
\end{equation}

* Weight binarization
\begin{equation}
    \tilde{w}_{rs}=
    \begin{cases}
      1, & \text{if}\ w_{rs} > \tau \\
      0, & \text{otherwise}
    \end{cases}
\end{equation}

* Weight reshaping
\begin{equation}
    \tilde{w}_{rs}=
    \begin{cases}
      w_{rs}-\tau, & \text{if}\ w_{rs} > \tau \\
      0, & \text{otherwise}
    \end{cases}
\end{equation}


## Graph-theoretical features
The following graph-theoretical features will be examined:
```{r, echo=F, warning=F, message=F}
text_tbl <- data.frame(
  Variable = c("Clustering coefficient", "Characteristic path length", "Modularity", 
            "Assortativity","Diameter", "Eigen-centrality"),
  Explanation = c("The clustering coefficient quantifies the extent of clustering in the network.", 
                  "The characteristic path length is the average paths length of all pairs of nodes.", 
                  "Modularity is a measure of the structure of networks or graphs which measures the strength of division of a network into modules (also called groups, clusters or communities). Networks with high modularity have dense connections between the nodes within modules but sparse connections between nodes in different modules.",
                  "The assortativity coefficient is the Pearson correlation coefficient of degree between pairs of linked nodes. Positive values of r indicate a correlation between nodes of similar degree, while negative values indicate relationships between nodes of different degree.", 
                  "The diameter of a graph is the length of the longest geodesic.", 
                  "The eigenvector centrality is a measure of the influence of a node in a network. Relative scores are assigned to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes.")
)

kbl(text_tbl) %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "30em")
```



# Mean Network

## Visualization
```{r, echo=F, message=F, warning=F}
xi=rep(0, q)
alpha0 = alpha[[1]]
alpha12 = alpha[[2]]
etai = alpha0 + c(xi%*%alpha12)
ox=etai
ox[ox!=0] = transform_to_beta(eta=etai[etai!=0], beta.pars = distr.params$beta, eta.pars = eta.params)
obeta0 = rep(1,p)   

Omegai=VecToSymMatrix(obeta0, ox)

sr=1
mii=numeric((p-1)*p/2); sr=1
for (s in 1:(p-1)) {
  for (r in (s+1):p) {
    # rho^2=pho
    pho=ox[sr]/sqrt(obeta0[s]*obeta0[r])
    mii[sr]=pho
    sr=sr+1
  }
}
mnet=VecToSymMatrix(1, mii, p)

mnet.bin <- mnet
mnet.bin[abs(mnet.bin)>0]<-1

ig <- graph_from_adjacency_matrix(mnet.bin, mode="undirected", diag=F)
co <- layout_nicely(ig)
plot(ig, main="Visualization of the mean network")
```

## Edge weight distribution

```{r , fig.show="hold", out.width="50%", echo=F, warning=F, fig.width=10, fig.height=6, fig.align='center', fig.cap="Histogram of the edge weight components (omega1, omega2) of mnet excluding zero entries"}
par(mar = c(4, 4, .1, .1))
hist(ox[ox!=0], main=expression(paste("Distribution of the mean covariance matrix ", Omega)), xlab="Weights", breaks=20, 
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, xim=c(0,1))
hist(mii[mii!=0], main=expression(paste("Distribution of the mean network ", Omega)), xlab="Weights", breaks=20,
     cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5, xlim=c(0,1))
```


## Thresholding and graph-theoretical features
```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=6, fig.cap="Individual-specific variability of edge weights due to the latent processes"}
# CC for threshold sequence
mnet = abs(mnet)

data.mnet <- wrapperThresholding(mnet, msize=p, thresh.seq, toMatrix = F)

data.mnet %>%
  filter(!Variable %in% "ncon") %>%
  mutate(Variable=fct_recode(Variable, "CC (weighted)"="cc",
                                          "Diameter"="dia", "CPL"="cpl",
                                          "Assortativity"="ass", "Modularity"="mod")) %>%
  ggplot(.,aes(x=Thresh, y=Value, col=Variable)) +
  geom_line() +
  theme_bw() +
  scale_color_brewer("Graph features", palette = "Dark2") +
  theme(text=element_text(size=14)) +
  facet_grid(vars(SparsMethod), vars(ThreshMethod))
```


```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=6, fig.cap="Number of edges per approach"}
data.mnet %>%
  filter(Variable %in% "ncon") %>%
  ggplot(.,aes(x=Thresh, y=Value, col=Variable)) +
  geom_line() +
  theme_bw() +
  scale_y_continuous("Number of edges") +
  theme(text=element_text(size=14), legend.position = "None") +
  facet_grid(vars(SparsMethod), vars(ThreshMethod))
```

# Individual-specific variation around the mean

```{r, echo=F, warning=F, message=F}
data.graph <- genIndivNetwork(n=sparams$n, p=sparams$p, q=sparams$q, alpha=sparams$alpha, 
                              distr.params=distr.params, eta.params = eta.params,
                              delta, mu=sparams$mu)
data.graph$GE = abs(data.graph$GE)
```


```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=6, fig.cap="Individual-specific variability of edge weights due to the latent processes"}
data.graph$GE %>%
  data.frame() %>%
  mutate(Subj=1:nrow(data.graph$GE)) %>%
  pivot_longer(cols=!Subj, names_to = "Weights", values_to = "Values") %>%
  filter(Values > 0) %>%
  ggplot(aes(x=Values, group=Subj, col=Subj)) +
  geom_density() +
  theme_bw() 
```

```{r, echo=F, warning=F, message=F}
# CC for threshold sequence
list.gvars <- lapply(1:nrow(data.graph$GE), function(x) 
  data.frame("Subj"=x,  wrapperThresholding(eweights=data.graph$GE[x,], msize=p, tseq=thresh.seq)))
data.gvars <- do.call(rbind,list.gvars)

data.gvars$Type <- "indiv"
data.mnet$Subj <- 0
data.mnet$Type <- "mean"

df <- data.frame(rbind(data.mnet, data.gvars)) %>%
   mutate(Type=fct_relevel(Type, c("mean", "indiv"))) %>%
   mutate(Variable=fct_recode(Variable, "Clustering Coefficient"="cc.w","Diameter"="dia", "Characteristic Path Length"="cpl", "Assortativity"="ass", "Modularity"="mod", "Number of edges"="ncon"))
gvars <- unique(df$Variable)
```


## Weight-based thresholding

```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=12, fig.caption="Individual-specific variability of graph-theoretical features for 100 individuals"}
plot.list <- list()
for(i in 1:length(gvars)){
 plot.list[[i]] <- df %>%
    data.frame() %>%
    filter(Variable %in% gvars[i] & SparsMethod %in% "weight-based") %>%
    ggplot(., aes(x = Thresh, y=Value, group=Subj, col=Type)) +
      geom_line(omega=0.5) +
      ggtitle(gvars[i]) +
      scale_color_manual(values=c("royalblue4","slategray2")) +
      theme_bw() +
      aes(group=rev(Subj)) +
      theme(text=element_text(size=12),legend.position="none", plot.title = element_text(hjust = 0.5)) +
      facet_wrap(~ThreshMethod)
}

grid.arrange(grobs = plot.list, ncol=1)
```


## Density-based thresholding
```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=12, fig.caption="Individual-specific variability of graph-theoretical features for 100 individuals"}
plot.list <- list()
for(i in 1:length(gvars)){
 plot.list[[i]] <- df %>%
    data.frame() %>%
    filter(Variable %in% gvars[i] & SparsMethod %in% "density-based") %>%
    ggplot(., aes(x = Thresh, y=Value, group=Subj, col=Type)) +
      geom_line(omega=0.5) +
      ggtitle(gvars[i]) +
      scale_color_manual(values=c("royalblue4","slategray2")) +
      theme_bw() +
      aes(group=rev(Subj)) +
      theme(text=element_text(size=12),legend.position="none",plot.title = element_text(hjust = 0.5)) +
      facet_wrap(~ThreshMethod)
}

grid.arrange(grobs = plot.list, ncol=1)
```

# References

<div id="refs"></div>
