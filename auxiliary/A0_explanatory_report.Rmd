---
title: 'Auxiliary analysis: General explanations and background of the simulation design'
author: "Mariella Gregorich"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    css: "../src/css_style.css"
    theme: cosmo
    number_sections: true
    keep_md: no
    fig_caption: true
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: true
      smooth_scroll: true
    highlight: tango
bibliography: ..\\src\\references.bib 
---



```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = F, warning=F, message=F)
set.seed(666)

source(here::here("src", "setup.R"))
source(here::here("src", "functions_main.R"))
source(here::here("src", "functions_aux.R"))

scn <- scenarios[11,] #22
p = scn$p
n = scn$n
po = (scn$p-1)*scn$p/2                                                                  
```

```{r}
# Preprocess
beta.params = unlist(scn$beta.params, use.names = F)
alpha0.params = unlist(scn$alpha0.params, use.names = F)
alpha12.params = unlist(scn$alpha12.params, use.names = F)
Z1.params = unlist(scn$Z1.params, use.names = F)
Z2.params = unlist(scn$Z2.params, use.names = F)
if(is.list(scn$dg.thresh)){dg.thresh = unlist(scn$dg.thresh)}

# -- Setup default network
dnw.params <- genDefaultNetwork(p, q, network.model=scn$network.model, beta.params, alpha0.params, alpha12.params, Z1.params, Z2.params)
```


# Background

## Data-generation
Individual-specific networks are constructed based on the principle that partial correlations between random Variables can be obtained through the inversion of the covariance matrix (precision matrix) and taking the ratio of appropriate entries from the precision matrix. It is inspired by the study by @xie2020identifying.

Each individual-specific precision matrix $\Omega_i(r,s)$ is currently constructed based on a transformed $p\times p$-dimensional scale-free default-structured matrix $\alpha_0$, where $p$ denotes the number of nodes. The default-structure matrix indicates the default connections between pairs of nodes which would be expected without individual-specific latent processes affecting or altering the structure and is thus equal for all individuals $i=1,..,n$. 

The default structure is derived from a Barabasi-Albert model with quadratic preferential attachment (power=2), a stochastic algorithm for scale-free network construction, such that a matrix is obtained with binary entries indicating the presence of a connection with 1 and the absence with 0. The entries of $\alpha_0$ corresponding to the presence of a connection are $\alpha_0(r,s)\sim N(0,1) , r, s=1,...,p$. 

The individual variability is introduced by two individual-specific latent variables $(Z_{1i},Z_{2i})$ and two $p \times p$-dimensional weight matrices $\alpha_1(r,s)$ and $\alpha_2(r,s)$ representing the edge-specific effect of the latent variables on the default structure matrix.

Individual-specific entries $\eta_i(r,s)$ for each node pair $(r,s)$ are then obtained by
\begin{equation}
\tag{1}
\eta_i(r,s) = \alpha_0(r,s) + \alpha_1(r,s)Z_{1i} + \alpha_2(r,s)Z_{2i}, 
\end{equation}
\begin{equation}
\alpha_0 \sim N(`r alpha0.params[1]`,`r alpha0.params[2]^2`) \\
\alpha_1, \alpha_2 \sim U(`r alpha12.params[1]`,`r alpha12.params[2]`) \\
Z_1 \sim N(`r Z1.params[1]`,`r Z1.params[2]^2`)\\
Z_2 \sim B(1,`r Z2.params[1]`)

\end{equation}

However, depending on the chosen parameters for the specific distribution, the boundaries of $\eta_i(r,s)$ will be arbitrary, hence, we want 
\begin{equation}
f: R:=\{\eta_i(r,s):(r,s) \in E\} \rightarrow (0,1) \\
or \\
f(\eta_i) \sim \beta(a,b)
\end{equation}

For this, we simulate $\alpha_0, \alpha_1, \alpha_2, Z_1 and Z_2$ from their corresponding distribution, compute the z-score $\eta_i(r,s)$ and then obtain its probability $p$ via the distribution function pnorm() at $\eta_i(r,s)$. 

In order to do so, we first have to derive the mean and variance of $\eta \sim N(\mu, \sigma)$ via
\begin{equation}
\mu=E(\eta)=E(\alpha_0+\alpha_1 Z_1+\alpha_2 Z_2) \\
\sigma=Var(\eta)=Var(\alpha_0+\alpha_1 Z_1+\alpha_2 Z_2)
\end{equation}
The final precision matrix $\Omega_i(r,s)$ is obtained by using the $\beta$-quantile function (inverse cumulative distribution function) predefined scaling factors $a$ and $b$ to determine the value corresponding to the $p$th-quantile of our beta distribution.

The partial correlation between node $s$ and $r$ defining the pairwise edge weight for individual $i$ is then constructed through the definition of partial correlation:
\begin{equation}
\tag{2}
w_i(r,s):=\rho_i(s,r)=-\frac{\Omega_i(s,r)}{\sqrt(\Omega_i(s,s)\Omega_i(r,r))}
\end{equation}
The diagonal elements of $\Omega_i$ can then be set to 1 in $\Omega_i$.


## Network sparsification

In the following we will differentiate between sparsification and thresholding as follows: 
Sparsification will describe the methodology to reduce the network density either by a

- weight-based approach: set edge weights below a fixed cut-off to 0
- density-based approach: set all edge weights not in the top X% to 0 

while thresholding describes the methodology of how retained edge weights are transformed either by

* Weight trimming
\begin{equation}
    \tilde{w}_{rs}=
    \begin{cases}
      w_{rs}, & \text{if}\ w_{rs} > \tau \\
      0, & \text{otherwise}
    \end{cases}
\end{equation}

* Weight binarization
\begin{equation}
    \tilde{w}_{rs}=
    \begin{cases}
      1, & \text{if}\ w_{rs} > \tau \\
      0, & \text{otherwise}
    \end{cases}
\end{equation}

* Weight reshaping
\begin{equation}
    \tilde{w}_{rs}=
    \begin{cases}
      w_{rs}-\tau, & \text{if}\ w_{rs} > \tau \\
      0, & \text{otherwise}
    \end{cases}
\end{equation}


## Graph-theoretical features
The following graph-theoretical features will be examined:
```{r, echo=F, warning=F, message=F}
text_tbl <- data.frame(
  Variable = c("Clustering coefficient", "Characteristic path length", "Modularity", 
            "Assortativity","Diameter", "Eigen-centrality"),
  Explanation = c("The clustering coefficient quantifies the extent of clustering in the network.", 
                  "The characteristic path length is the average paths length of all pairs of nodes.", 
                  "Modularity is a measure of the structure of networks or graphs which measures the strength of division of a network into modules (also called groups, clusters or communities). Networks with high modularity have dense connections between the nodes within modules but sparse connections between nodes in different modules.",
                  "The assortativity coefficient is the Pearson correlation coefficient of degree between pairs of linked nodes. Positive values of r indicate a correlation between nodes of similar degree, while negative values indicate relationships between nodes of different degree.", 
                  "The diameter of a graph is the length of the longest geodesic.", 
                  "The eigenvector centrality is a measure of the influence of a node in a network. Relative scores are assigned to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes.")
)

kbl(text_tbl) %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "30em")
```

## Outcome modelling

Based on the obtained individual-specific networks, graph-theoretical features can be associated with an outcome of interest as follows:

- **OPT**: Thresholding cut-offs between 0 and 1 taken in equidistant steps are sequentially applied to the networks and resulting graph-theoretical features are separately associated with the outcome. The final threshold is the one with the best prediction performance (e.g. RMSE).
- **AVG**: Thresholding cut-offs between 0 and 1 taken in equidistant steps are sequentially applied to the networks and resulting graph-theoretical features are averaged for each individual and then related to the outcome.
- **FLEX**: Thresholding cut-offs between 0 and 1 taken in equidistant steps are sequentially applied to the networks and the resulting graph-theoretical feature sequence obtained for each individual is related to the outcome through a functional data analysis (FDA) approach.

# Example

In the following chapter, special aspects of the simulation study are considered specifically for one run in order to obtain insights about parameter distributions and the general internal behavior of the approaches.

## Parameter

```{r}
tbl_params <- data.frame("Parameter"=colnames(scn)[c(1:6,8,12:15)],
                         "Values" =unlist(sapply(scn[1,c(1:6,8,12:15)], as.character)))

tbl_params %>%
  kbl(caption="Parameter of the scnario", escape = F, row.names = F) %>%
  row_spec(0, bold = T) %>%
  kable_classic(full_width = F, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```

## Simulation design

### Edge weight distribution

```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=6, fig.height=4, fig.cap="Individual-specific variability of edge weights due to the latent processes"}
data.graph <- generate_data(setting=scn$setting,
                            n = scn$n, 
                            p = scn$p, 
                            q = scn$q,
                            alpha = dnw.params$alpha, 
                            mu = dnw.params$mu, 
                            eta.params = dnw.params$eta.params,
                            beta.params = unlist(scn$beta.params),
                            Z1.params = unlist(scn$Z1.params),
                            Z2.params = unlist(scn$Z2.params),
                            b0 = scn$b0,
                            b1 = scn$b1,  
                            b2 = scn$b2,
                            eps.y = scn$eps.y, 
                            eps.g = scn$eps.g,  
                            dg.thresh = scn$dg.thresh,
                            dg.spars = scn$dg.spars,
                            step.size = scn$step.size)
data.fun <- data.graph$fun
data.graph <- data.graph$data

data.ews <- data.graph %>%
  dplyr::select(Z.Z2,paste0("GE.",1:po)) %>%
  data.frame() %>%
  mutate(ID=1:nrow(data.graph),
         Z.Z2 = as.factor(Z.Z2)) %>%
  pivot_longer(cols=!c(ID,Z.Z2), names_to = "Weights", values_to = "Values") %>%
  filter(Values != 0) 

data.ews %>%
  ggplot(aes(x=Values, group=ID, col=ID)) +
  geom_density() +
  scale_x_continuous("Edge weight", lim=c(0,1)) +
  scale_y_continuous("Density") +
 # scale_color_manual("Binary latent process Z2", values = c("royalblue4", "steelblue2")) +
  theme_bw() +
  theme(text=element_text(size=20))
ggsave(file =here::here("output", "_figs", "/fig_density_indiv.tiff"),
       width=1.5*200, height=1*200, units="mm", dpi=350, compression = "lzw")
```

<br>

```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=6, fig.height=4, fig.cap="Edge weight distribution"}
data.graph %>%
  select(paste0("GE.",1:po)) %>%
  data.frame() %>%
  mutate(ID=1:nrow(data.graph)) %>%
  pivot_longer(cols=!ID, names_to = "Weights", values_to = "Values") %>%
  filter(Values > 0) %>%
  ggplot(aes(x=Values)) +
  geom_density() +
  theme_bw() 
```

<br>

```{r}
vec_avg <- data.graph %>%
  select(paste0("GE.",1:po)) %>%
  colMeans()

mat <- VecToSymMatrix(diag.entry = 1, side.entries = vec_avg, mat.size = p)
pheatmap::pheatmap(mat, treeheight_row = 0, treeheight_col = 0)
```


```{r}
indiv.graph <- data.graph %>%
  select(paste0("GE.",1:po))%>%
  slice_sample(n=1)

indiv.mat <- VecToSymMatrix(diag.entry = 0, side.entries = as.vector(indiv.graph), mat.size = scn$p)
pheatmap::pheatmap(indiv.mat, treeheight_row = 0, treeheight_col = 0)

```

<br>

### Graph-theoretical features 

```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=12, fig.height=6, fig.caption="Individual-specific variability of graph-theoretical features for XXX individuals"}
# Extract network data
po = (p-1)*p/2     
k=5
data.network <- data.graph[,paste0("GE.noisy.",1:po)]
data.network.true <- data.graph[,paste0("GE.",1:po)]

data.graph$fold <- cvFolds(length(unique(data.graph$ID)), K=k)$which
options(dplyr.summarise.inform = FALSE)

# CC for threshold sequence
data.gvars <- wrapperThresholding(df=data.network, msize=p, step.size=step.size)
data.gvars.true <- wrapperThresholding(df=data.network.true, msize=p, step.size=step.size)

# Add outcome Y
data.gvars <- merge(data.graph[,c("ID","Y", "X", "fold")], data.gvars, by="ID") %>%
  mutate(Value=ifelse(is.nan(Value), NA, Value),
         Noise = "true") %>%
  mutate_at(vars(Thresh, Y, Value), as.numeric) %>%
  filter(Variable %in% "cc.uw") 
data.gvars.true <- merge(data.graph[,c("ID","Y", "X", "fold")], data.gvars.true, by="ID") %>%
  mutate(Value=ifelse(is.nan(Value), NA, Value),
         Noise = "none",
         ID = ID +75) %>%
  mutate_at(vars(Thresh, Y, Value), as.numeric) %>%
  filter(Variable %in% "cc.uw") 

data.gvars %>% 
  ggplot(aes(x=Thresh, y=Value, group=ID)) +
  geom_line(col="grey66") +
  scale_x_continuous("Threshold") +
  scale_y_continuous("Clustering coefficient") +
  theme_bw() +
  facet_grid(~SparsMethod) +
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size=26))
ggsave(file = here::here("output", "_figs", "/fig_edge_weight_dist.tiff"),
       width=1.75*200, height=1*200, units="mm", dpi=350, compression = "lzw")
```


```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=12, fig.height=6, fig.caption="Individual-specific variability of graph-theoretical features for XXX individuals grouped by magnitude of noise for edge weights"}
dataG <- data.frame(rbind(data.gvars, data.gvars.true))
dataG %>% 
  ggplot(aes(x=Thresh, y=Value, group=ID, col=Noise)) +
  geom_line() +
  scale_x_continuous("Threshold") +
  scale_y_continuous("Clustering coefficient") +
  theme_bw() +
  facet_grid(~SparsMethod) +
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size=26))
```



### Outcome

```{r, fig.align='center', fig.width=6, fig.height=4, fig.cap="Distribution of the outcome variable"}
data.gvars %>%
  dplyr::select(ID, Y) %>%
  distinct(Y, keep.all=T) %>%
  ggplot(aes(x=Y))+
  geom_histogram(col="black", fill="gray80") +
  ggtitle("Histogram of the outcome Y") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size=14))
```
<br>

```{r, fig.align='center', fig.width=6, fig.height=4, fig.cap="Distribution of the outcome variable with and without noise"}
data.graph %>%
  dplyr::select(Y.true, Y) %>%
  melt() %>%
  ggplot(aes(x=value, fill=variable)) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    theme_bw() +
    labs(fill="")
```


### Functional form of sequence

In the following selection, the three functional forms for data generation using the sequence of graph-theoretical features are first illustrated. In the following, the average RMSE function for each threshold value t is first calculated in an unstandardized and then in a standardized way. The calculation is performed for each threshold t by taking the root of the mean squared difference between the true beta(t) value at t and the estimated over all iterations.

```{r, echo=F, warning=F, message=F}
b1 <- as.numeric(scn$b1[1])
thr.grid = seq(0,1,0.0005)
true.opt = ifelse(thr.grid==0.25, scn$b1, NA)
true.flat = rep(b1*2,length(thr.grid))
true.halfsine = sin(thr.grid*pi)*b1*2
true.sine = sin(thr.grid*pi*4)*b1*2
true_fun <- data.frame("thresh"= thr.grid,
                       "flat"= true.flat,
                       "half-sine"=true.halfsine,
                       "sine"=true.sine)

thr.weight <- round(runif(scn$n, min=0.1, max=0.4),3)
true.random <- data.frame("ID"=data.graph$ID, "thresh"=thr.weight, "random"=scn$b1, "DGM"="random")

true_fun_melted <- melt(true_fun, id.vars = "thresh") %>%
  rename("DGM"=variable) %>%
  mutate(DGM=fct_recode(DGM, "half-sine"="half.sine"))
```


```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=3, fig.cap="The three true functional forms used in the data-generating mechanism to generated the outcome based on a graph-theoretical feature sequence derived by sequential weight-based sparsification"}
true.opt <- data.frame("ID"=scn$n, "thresh"=thr.grid, "value"=ifelse(thr.grid==0.25, scn$b1, NA), "DGM"="single")
true.random <- data.frame("ID"=data.graph$ID, "thresh"=thr.weight, "value"=scn$b1, "DGM"="random")
true.halfsine = sin(thr.grid*pi)*b1*2
true.hs <- data.frame("ID"=scn$n, "thresh"=thr.grid, "value"=true.halfsine, "DGM"="half-sine")

true.scn <- data.frame(rbind(true.opt, true.random, true.hs)) %>%
  mutate(DGM=fct_relevel(DGM, c("single", "random", "half-sine")))

p1 <- true.scn %>%
  filter(DGM %in% "single") %>%
  ggplot(aes(x=thresh, y=value, group=ID)) +
  geom_vline(xintercept = 0.25, linetype=2, col="grey") +
  geom_point(col="blue") +
  geom_line(data=data.frame(ID=c(rep(1, length(seq(0,0.24,0.01))), rep(2, length(seq(0.26,1,0.01)))),
                            thresh=c(seq(0,0.24,0.01),seq(0.26,1,0.01)),value=0), col="blue") +
  theme_bw() +
  facet_grid(~DGM, labeller = label_both)+
  scale_x_continuous("", lim=c(0,1)) +
  scale_y_continuous("", lim=c(-20,20)) +
  theme(legend.position = "None",
        text=element_text(size=16))
p2 <- true.scn %>%
  dplyr::filter(DGM %in% "random" & ID %in% c(1,44, 249, 150, 250)) %>%
  ggplot(aes(x=thresh, y=value, col=ID)) +
  geom_point(size=4) +
  theme_bw() +
  geom_vline(xintercept = c(0.1, 0.4), linetype=2, col="grey") +
  facet_grid(~DGM, labeller = label_both)+
  geom_label(data = data.frame(ID=1, thresh=0.5, value=-10),label = expression(t[opt,i]*" for n=5!"), size=5) +
  scale_x_continuous("Threshold", lim=c(0,1)) +
  scale_y_continuous("", lim=c(-20,20)) +
  theme(legend.position = "None",
        text=element_text(size=16),
        strip.text.x = element_text(size = 16))
p3 <- true.scn %>%
  filter(DGM %in% "half-sine") %>%
  ggplot(aes(x=thresh, y=value, col=ID)) +
  geom_line(col="blue") +
  theme_bw() +
  facet_grid(~DGM, labeller = label_both)+
  scale_x_continuous("", lim=c(0,1)) +
  scale_y_continuous("", lim=c(-20,20)) +
  theme(legend.position = "None",
        text=element_text(size=16))
p <- grid.arrange(p1,p2,p3, nrow=1)

```

<br>

```{r, echo=F, warning=F, message=F, fig.align='center', fig.width=8, fig.height=3, fig.cap="The three true functional forms used in the data-generating mechanism to generated the outcome based on a graph-theoretical feature sequence derived by sequential weight-based sparsification"}
ggplot(true_fun_melted, aes(x=thresh, y=value)) +
  geom_line(col="blue") +
  ggtitle("True functional form of data generation") +
  facet_grid(~ DGM, labeller = label_both) +
  theme_bw() +
  scale_x_continuous("Threshold t") +
  scale_y_continuous(paste0("Coeficient function \u03b2(t)")) +
  theme(text = element_text(size=16))
```



<br>

## Methods

```{r}
true.params <- data.frame("ID"= data.graph$ID,
                         "DGMethod"=data.graph$dg.method,
                         "Thresh"=data.graph$dg.threshold,
                         "SparsMethod"="weight-based",
                         "ThreshMethod"="trim",
                         "Variable"="cc.uw")
threshold.OPT <- data.frame(SparsMethod = c("weight-based", "density-based"), 
                        threshold.lo =c(0, .25),
                        threshold.up =c(.75, 1))
threshold.AVG <- data.frame(SparsMethod = c("weight-based", "density-based"), 
                            threshold.lo =c(.1, .6),
                            threshold.up =c(.4, .9))
dg.method <- data.graph$dg.method[1]
adjust <- ifelse(setting %in% "uni", FALSE, TRUE)
  

# --  Oracle model
# Data preparation for oracle model
  # Data preparation for oracle model
  if(dg.method %in% c("single","random")){
    data.oracle <- data.gvars %>%
      filter(SparsMethod == true.params$SparsMethod & ThreshMethod == true.params$ThreshMethod &
               Variable == true.params$Variable) %>%
      group_by(Thresh) %>%
      mutate("true.t"=data.graph$dg.threshold) %>%
      filter(Thresh == round(true.t,2)) %>%
      dplyr::select(!true.t)
  }else if(dg.method %in% "func"){
    mat.gvars <- data.gvars %>%
      filter(SparsMethod == true.params$SparsMethod & ThreshMethod == true.params$ThreshMethod &
               Variable == true.params$Variable) %>%
      dplyr::select(ID, Thresh, Value) %>%
      arrange(Thresh) %>%
      pivot_wider(names_from = "Thresh", values_from = "Value")
    
    prod.betaX.true <- rowSums(t(data.fun$betafn.true * t(mat.gvars[,-1])))
    
    data.oracle <- data.gvars %>%
      filter(SparsMethod == true.params$SparsMethod & ThreshMethod == true.params$ThreshMethod &
               Variable == true.params$Variable & Thresh == 0) %>%
      mutate(Value = prod.betaX.true*(b1/5))
  }

data.oracle <- data.oracle %>%
  group_by(ThreshMethod, SparsMethod, Variable) %>%
  nest() %>%
  mutate(res=lapply(data, function(x) rbind(perform_AVG(dat=x, k=k, adjust=F), 
                                            perform_AVG(dat=x, k=k, adjust=T)))) %>%
  unnest(res) %>%
  mutate("AnaMethod"="Oracle",
         "Spline"=NA,
         Thresh=ifelse(length(dg.thresh)>1, "random", as.character(true.params$Thresh[1])))

# --  Null model
data.null <- data.graph %>%
  dplyr::select(ID, fold, Y, X) %>%
  mutate(ThreshMethod = true.params$ThreshMethod,
         SparsMethod = true.params$SparsMethod,
         Variable = true.params$Variable,
         Value = mean(Y)) %>%
  group_by(ThreshMethod, SparsMethod, Variable) %>%
  nest() %>%
  mutate(res=lapply(data, function(x) rbind(perform_AVG(dat=x, k=k, adjust=F),
                                            perform_AVG(dat=x, k=k, adjust=T)))) %>%
  unnest(res) %>%
  mutate("AnaMethod"="Null",
         Thresh=as.character(Thresh)) 


# -- Pick model with best RMSE
data.OPT <- data.gvars  %>% 
  left_join(threshold.OPT, by = 'SparsMethod') %>%
  filter(Thresh >= threshold.lo & Thresh <= threshold.up) %>%
  group_by(SparsMethod, ThreshMethod, Variable) %>%
  nest() %>%
  mutate(res=lapply(data, function(x) rbind(perform_OPT(dat=x, k=k, adjust=F), 
                                            perform_OPT(dat=x, k=k, adjust=T)))) %>%
  unnest(res, keep_empty = T) %>%
  mutate("AnaMethod"="OPT",
         Thresh=as.character(Thresh)) 


# --  Average feature across threshold sequence
data.AVG <- data.gvars %>%
  left_join(threshold.AVG, by = 'SparsMethod') %>%
  filter(Thresh >= threshold.lo & Thresh <= threshold.up) %>%
  group_by(SparsMethod, ThreshMethod, Variable, ID, Y, X, fold) %>%
  summarise("Value.avg"=mean(Value, na.rm=T)) %>%
  rename(Value=Value.avg) %>%
  group_by(SparsMethod, ThreshMethod, Variable) %>%
  nest() %>%
  mutate(res=lapply(data, function(x) rbind(perform_AVG(dat=x, k=k, adjust=F), 
                                            perform_AVG(dat=x, k=k, adjust=T)))) %>%
  unnest(res, keep_empty = T) %>%
  mutate("AnaMethod"="AVG",
         Thresh=as.character(Thresh)) 


# --  Functional data analysis approach
data.FLEX <- data.gvars %>%
  arrange(Thresh) %>%
  mutate(Thresh=paste0("T_",Thresh),
         Y = as.numeric(as.character(Y))) %>%
  pivot_wider(values_from = Value, names_from = Thresh) %>%
  group_by(SparsMethod, ThreshMethod, Variable) %>%
  nest() %>%
  mutate(res=lapply(data, function(x) rbind(perform_FLEX(data.fda=x, k=k, nodes=20, adjust=F, bs.type="ps"),
                                            perform_FLEX(data.fda=x, k=k, nodes=20, adjust=T, bs.type="ps")))) %>%
  unnest(res) %>%
  mutate("AnaMethod"="FLEX",
         Thresh=as.character(Thresh))


```



## Results

Results of one iteration with a true R2 of `r round_0(data.graph$true.R2[1],2)` and a true threshold cut-off of `r data.graph$true.threshold[1] `

### Functional form $\beta(t)$

#### Penalized splines

```{r, fig.align='center', fig.width=8, fig.height=5, fig.cap="Coefficient function of the FLEX approach with penalized splines and 20 nodes"}

data.FLEX.coeff <- data.FLEX %>%
  select(Variable, AnaMethod, Adjust, ThreshMethod, SparsMethod, Coef) %>%
  unnest(Coef) %>%
  reduce(data.frame) %>%
  `colnames<-`(c("Variable", "AnaMethod", "Adjust","ThreshMethod", "SparsMethod", 
                 "fda.thresh", "fda.est", "fda.se", "fda.sd.Xt")) %>%
  merge(., data.fun, by.x="fda.thresh", by.y="steps")
```

```{r, fig.align='center', fig.width=8, fig.height=6, fig.cap="Unstandardized coefficient function modelled for the clustering coefficient by penalized splines with 20 nodes"}
data.FLEX.coeff %>%
  filter(Variable %in% "cc.uw") %>%
  mutate(fda.est.lo=fda.est - 1.96 * fda.se,
         fda.est.up=fda.est + 1.96 * fda.se) %>%
  ggplot(aes(x=fda.thresh, y=fda.est, ymin=fda.est.lo, ymax=fda.est.up, col=SparsMethod)) +
  geom_line() +
  geom_ribbon(alpha=0.1) +
  scale_y_continuous("Coefficient function") +
  scale_x_continuous("Threshold") +
  facet_grid(SparsMethod~Adjust, scales = "free_y") +
  theme_bw() 
```

<br>

```{r, fig.align='center', fig.width=8, fig.height=6, fig.cap="Standardized coefficient function modelled for the clustering coefficient by penalized splines with 20 nodes"}
data.FLEX.coeff %>%
  filter(Variable %in% "cc.uw") %>%
  mutate(fda.est.std = fda.est * fda.sd.Xt,
         fda.est.lo=fda.est - 1.96 * fda.se,
         fda.est.up=fda.est + 1.96 * fda.se,
         fda.est.std.lo=fda.est.lo * fda.sd.Xt,
         fda.est.std.up=fda.est.up * fda.sd.Xt) %>%
  ggplot(aes(x=fda.thresh, y=fda.est.std, ymin=fda.est.std.lo, ymax=fda.est.std.up, col=SparsMethod)) +
  geom_line() +
  geom_ribbon(alpha=0.1) +
  scale_y_continuous("Coefficient function") +
  scale_x_continuous("Threshold") +
  theme_bw() +
  facet_grid(SparsMethod~Adjust, scales = "free_y")
```

<br>

```{r, fig.align='center', fig.width=8, fig.height=5, fig.cap="Product of coefficient function and functional covariate of the FLEX approach with penalized splines and 20 nodes"}
mat.gvars <- data.gvars %>%
  arrange(Thresh)%>%
  mutate(Thresh=paste0("T_",Thresh)) %>%
  pivot_wider(values_from = Value, names_from = Thresh) %>%
  group_by(SparsMethod, ThreshMethod, Variable) %>%
  nest() 
mat.gvars <- as.data.frame(mat.gvars[1,]$data)
mat.gvars <- apply(mat.gvars[,4:54],2, as.numeric)
betat.hat <- as.numeric(data.FLEX.coeff[data.FLEX.coeff$SparsMethod == "weight-based",]$fda.est)

prod.betaX.hat <- t(betat.hat * t(mat.gvars))

prod.betaX.hat <- prod.betaX.hat %>%
  melt() %>%
  mutate("grid"= as.numeric(str_remove(Var2, "T_"))) %>%
  dplyr::select(Var1, value, grid) %>%
  `colnames<-`(c("ID", "value", "grid")) %>%
  mutate("group"="estimate")

prod.betaX.true <- t(data.fun$betafn.true * t(mat.gvars)) *scn$b1/5

prod.betaX.true <- data.frame("ID"=1:n, prod.betaX.true) %>%
  melt(id.vars="ID") %>%
  mutate("grid"=as.numeric(str_remove(as.character(variable), "T_"))) %>%
  dplyr::select(ID, value, grid) %>%
  `colnames<-`(c("ID", "value", "grid")) %>%
  mutate("group"="true")


prod.betaX <- data.frame(rbind(prod.betaX.hat, prod.betaX.true))

p <- ggplot(data=prod.betaX, aes(x=grid, y=value, group=ID, col=ID)) +
   geom_line() +
   facet_grid(~group) +
   theme_bw() +
  theme(text=element_text(size=16))

if(all(is.na(prod.betaX.true$value))){
  p <- p + geom_label(data = data.frame(ID=1, grid=0.5, value=mean(prod.betaX$value, na.rm=T), group="true"),
                                     label = "No true functional form selected!", size=5)
} 
p
```

<br>

### Overall

```{r}
data.results <- data.frame(rbind(
    data.null[,c("AnaMethod", "Adjust", "SparsMethod", "ThreshMethod", "Thresh","Variable","RMSE", "R2", "CS")],
    data.oracle[,c("AnaMethod","Adjust", "SparsMethod", "ThreshMethod", "Thresh","Variable","RMSE", "R2", "CS")],
    data.OPT[,c("AnaMethod","Adjust", "SparsMethod", "ThreshMethod", "Thresh","Variable","RMSE", "R2", "CS")],
    data.AVG[,c("AnaMethod","Adjust", "SparsMethod", "ThreshMethod", "Thresh","Variable","RMSE", "R2", "CS")],
    data.FLEX[,c("AnaMethod","Adjust", "SparsMethod", "ThreshMethod", "Thresh","Variable","RMSE", "R2", "CS")]))
```


```{r}
data.results %>%
  filter(SparsMethod %in% "weight-based") %>%
  mutate_at(7:9, as.numeric) %>%
    mutate_at(7:9, round_0, 3) %>%
  arrange(RMSE) %>%
  kbl(caption="Results of one iteration", 
      escape = F, row.names = F) %>%
  row_spec(0, bold = T) %>%
  column_spec(c(3:6), extra_css="text-align: center") %>%
  kable_classic(full_width = F, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```

<br>

```{r}
data.results %>%
  filter(SparsMethod %in% "density-based") %>%
  mutate_at(7:9, as.numeric) %>%
    mutate_at(7:9, round_0, 3) %>%
  arrange(RMSE) %>%
  kbl(caption="Results of one iteration", 
      escape = F, row.names = F) %>%
  row_spec(0, bold = T) %>%
  column_spec(c(3:6), extra_css="text-align: center") %>%
  kable_classic(full_width = F, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```


# References

<div id="refs"></div>