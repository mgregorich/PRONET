---
title: 'Auxiliary analysis: Functional regression'
author: "Mariella Gregorich"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    css: "../src/css_style.css"
    theme: cosmo
    number_sections: true
    keep_md: no
    fig_caption: true
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: 
      collapsed: true
      smooth_scroll: true
    highlight: tango
bibliography: ..\\src\\references.bib 
---



```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = F, warning=F, message=F)

set.seed(1234)
source(here::here("src", "functions_main.R"))
source(here::here("src", "functions_aux.R"))

source(here::here("src", "setup.R"))

scn <- scenarios[19,]
po = (scn$p-1)*scn$p/2    
p = scn$p
n = scn$n
```

```{r}
# Preprocess
beta.params = unlist(scn$beta.params, use.names = F)
alpha0.params = unlist(scn$alpha0.params, use.names = F)
alpha12.params = unlist(scn$alpha12.params, use.names = F)
Z1.params = unlist(scn$Z1.params, use.names = F)
Z2.params = unlist(scn$Z2.params, use.names = F)
if(is.list(scn$dg.thresh)){dg.thresh = unlist(scn$dg.thresh)}

# -- Setup default network
dnw.params <- genDefaultNetwork(p, q, beta.params, alpha0.params, alpha12.params, Z1.params, Z2.params)
```


# Background

Here, we are interested in functional regression, in partical scalar-on-function (SOF) regression. The R package refund* - REgression with FUNctional Data - includes functions and computational methods for “scalar-on-function” regression: y ∼ x(s). 

The generalized functional linear model for linear regression that relates the outcome $Y_i$ of individual $i$ to a functional covariate $X_i(t)$ can be written as
$$ Y_i \sim N(\mu_i,\eta) $$
$$ \mu_i=\alpha + \int_0^1 X_i(s)\beta(s)ds$$
However, $X_i(t)$ will only ever be observed on a grid rather than be truly functional.

The coefficient function $\beta(t)$ is modeled using a spline basis $\phi(t)=\{\phi_1(t),...,\phi_K(t)\}$,
$$\beta(t)=\sum_{k=1}^K b_k\phi_k(t)= \boldsymbol{\phi}(t)\boldsymbol{b} $$
Thus,
$$ g(\mu_i)=\alpha + \int_0^1 X_i(s)\boldsymbol{\phi}(s)\boldsymbol{b}~ds$$


The coefficient function $\beta(.)$ is a smooth weighting scheme which, when applied to the individual-specific predictors $X_i(.)$, is
most predictive of the outcome. Weights close to zero de-emphasize indiviual-level areas that are not predictive of the outcome, while large relative weights emphasize areas of the curve that are most predictive of the outcome @goldsmith2011penalized.


# Data generation

## Parameter

```{r}
tbl_params <- data.frame("Parameter"=colnames(scn)[c(1:5,7,11:14)],
                         "Values" =as.character(scn[1,c(1:5,7,11:14)]))

tbl_params %>%
  kbl(caption="Parameter of the scnario", escape = F, row.names = F) %>%
  row_spec(0, bold = T) %>%
  kable_classic(full_width = F, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```


## Simulation design

```{r, echo=F, warning=F, message=F}
data.graph <- generate_data(setting=scn$setting,
                            n = scn$n, 
                            p = scn$p, 
                            q = scn$q,
                            alpha = dnw.params$alpha, 
                            mu = dnw.params$mu, 
                            eta.params = dnw.params$eta.params,
                            beta.params = unlist(scn$beta.params),
                            Z1.params = unlist(scn$Z1.params),
                            Z2.params = unlist(scn$Z2.params),
                            b0 = scn$b0,
                            b1 = scn$b1,  
                            b2 = scn$b2,
                            eps.y = scn$eps.y, 
                            eps.g = scn$eps.g,  
                            dg.thresh = scn$dg.thresh,
                            dg.spars = scn$dg.spars,
                            step.size = scn$step.size)

data.fun <- data.graph$fun
data.graph <- data.graph$data

k=5
df <- data.graph
data.network <- df[,paste0("GE.noisy.",1:po)]
df$ID <- 1:n
df$fold <- cvFolds(length(unique(df$ID)), K=k)$which


# CC for threshold sequence
data.gvars <- wrapperThresholding(df=data.network, msize=p, step.size=scn$step.size)

data.gvars <- merge(df[,c("ID","Y", "fold")], data.gvars, by="ID") %>%
  mutate(Value=ifelse(is.nan(Value), NA, Value)) %>%
  mutate_at(vars(Thresh, Y, Value), as.numeric) %>%
  filter(Variable %in% "cc.uw")
```


<br>

```{r, fig.align='center', fig.width=8, fig.height=5, fig.cap="Distribution of the predictor function obtained through varying sparsification and thresholding techniques. The red line indicates the average behaviour of the invidual-specific functional covariate."}

data.gvars %>% 
  ggplot(aes(x=Thresh, y=Value, group=ID)) +
  geom_line(col="gray80") +
  scale_x_continuous("Threshold") +
  scale_y_continuous("Clustering coefficient") +
  ggtitle("Individual-specific network analysis") +
  facet_grid(SparsMethod ~ThreshMethod) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size=14))

```



```{r, fig.align='center', fig.width=8, fig.height=5, fig.cap="Distribution of the scalar (outcome) and the function (predictor)"}
data.gvars %>%
  dplyr::select(ID, Y) %>%
  distinct(Y, keep.all=T) %>%
  ggplot(aes(x=Y))+
  geom_histogram(col="black", fill="gray80") +
  ggtitle("Histogram of the outcome Y") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size=14))
```
## Functional form of sequence

```{r, echo=T, fig.align='center', fig.width=8, fig.height=5, fig.cap="True beta coefficient funcion for threshold sequence"}
step.size <- 0.02
thr.weight <- NA
thr.grid <- seq(0,1, step.size)
betafn1.true <- sin(thr.grid*pi)*2

plot(thr.grid, betafn1.true)
```

# Methods

## Functional regression
[Refund-Package](https://cran.r-project.org/web/packages/refund/refund.pdf) \

[Smoothing terms for the functional covariate](https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/smooth.terms.html)



```{r}
list.fit.fda <- list()
i=1
for(sm in unique(data.gvars$SparsMethod)){
  for(tm in unique(data.gvars$ThreshMethod)){
    # sm="weight-based"; tm="bin"
    data.func <- data.gvars %>%
      filter(SparsMethod %in% sm & ThreshMethod %in% tm) %>%
      arrange(Thresh) %>%
      pivot_wider(values_from = Value, names_from = Thresh) %>%
      select(!(Variable:SparsMethod))
      
    flength=length(seq(0,1,0.02))
    data.func$X <- as.matrix(data.func[,(ncol(data.func)-flength+1):ncol(data.func)])
    data.func <- data.func %>% 
      dplyr::select(ID,Y,X)
    
    list.fit.fda[[i]] <- list("SparsMethod"=sm, "ThreshMethod"=tm, 
                              "fit"=refund::pfr(Y ~ lf(X, k = 20, bs="ps"), method="REML", data=data.func, family="gaussian"),
                              "data"=data.func$X )
    i=i+1
  }
}
```



<br>

```{r, echo=T, fig.align='center', fig.width=8, fig.height=5, fig.cap="Beta coefficient funcion from all functional regression models"}
list.fda.coef <- list()
for(j in 1:length(list.fit.fda)){
  coef <- coef(list.fit.fda[[j]][[3]])
  coef$value.lo <- coef$value - 1.96*coef$se
  coef$value.up <- coef$value + 1.96*coef$se
  list.fda.coef[[j]] <- data.frame("SparsMethod"=list.fit.fda[[j]]$SparsMethod, 
                          "ThreshMethod"=list.fit.fda[[j]]$ThreshMethod, 
                          coef)
}
data.coef <- do.call(rbind, list.fda.coef)

ggplot(data.coef, aes(x=X.argvals, y=value))+
  geom_line() +
  geom_ribbon(ggplot2::aes(ymin = value.lo, ymax = value.up), alpha = 0.1) +
  scale_x_continuous("Threshold", breaks=seq(0,1,0.2)) +
  scale_y_continuous("Estimated coefficient function beta(t)") +
  theme_bw() +
  facet_grid(SparsMethod~ThreshMethod, scales="free_y")
```

<br>

```{r, fig.align='center', fig.width=8, fig.height=6, fig.cap="Calibration plot"}
list.fda.pred <- list()
j=1
for(j in 1:length(list.fit.fda)){
  yhat <- list.fit.fda[[j]][[3]]$fitted.values
  y <- list.fit.fda[[j]][[3]]$model$Y
  list.fda.pred[[j]] <- data.frame("SparsMethod"=list.fit.fda[[j]]$SparsMethod, 
                          "ThreshMethod"=list.fit.fda[[j]]$ThreshMethod, 
                          "Y"=y, "Yhat"=yhat)
}
data.pred <- do.call(rbind, list.fda.pred) 

# Calibration
data.pred %>%
  ggplot(aes(x=Y, y=Yhat))+
  geom_point(shape=1) + 
  geom_abline(intercept = 0, col="red3") +
  theme_bw() +
  facet_grid(SparsMethod~ThreshMethod, scales="free_y")
  
```

<br>

```{r}
list.fda.perf <- list()
j=1
for(j in 1:length(list.fit.fda)){
  r.sq <- summary(list.fit.fda[[j]][[3]])$r.sq
  yhat <- list.fit.fda[[j]][[3]]$fitted.values
  y <- list.fit.fda[[j]][[3]]$model$Y
  rmse <- calc_rmse(y, yhat)
  cs <- calc_cs(y,yhat)
  list.fda.perf[[j]] <- data.frame("SparsMethod"=list.fit.fda[[j]]$SparsMethod, 
                          "ThreshMethod"=list.fit.fda[[j]]$ThreshMethod, 
                          "R2"=r.sq, "RMSE"=rmse, "CS"=cs)
}
data.FDA <- do.call(rbind, list.fda.perf) 
row.names(data.FDA) <- NULL

data.FDA %>%
  mutate_at(3:5, round_0, digits=4) %>%
  kbl(caption="Performance of the functional data approach", escape = F) %>%
  row_spec(0, bold=T) %>%
  kable_classic(full_width = T, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)

```

<br>

**Example of a summary output using the following approach: **

- Sparsification method = `r list.fit.fda[[1]]$SparsMethod`
- Threshold method = `r list.fit.fda[[1]]$ThreshMethod`



```{r, echo=T, fig.align='center', fig.width=5, fig.height=3, fig.cap="Functional term = beta(t) * X"}
V1 <- c(list.fda.coef[[1]]$value) 
M1 <- as.matrix(list.fit.fda[[1]]$data)

beta.times.X <- M1 %*% diag(V1) %>%
  data.frame() %>%
  `colnames<-`(seq(0,1,0.02)) %>%
  mutate(ID=1:n) %>%
  pivot_longer(cols = !ID, names_to = "Thresh", values_to = "Value")

ggplot(beta.times.X, aes(x=Thresh, y=Value, group=ID)) +
  geom_line() +
  theme_bw() +
  scale_x_discrete(breaks=seq(0,1,0.1))
```



## Best RMSE approach
The bRMSE-approach fits a univariable linear regression model for each sparsification method (SparsMethod $\in$ {density-base, weight-based}), each thresholding method (ThreshMethod $\in$ {trim, bin, resh}) and for each threshold (Thresh $\in$ [0,1]). Then, the root mean squared error (RMSE) for each of these models is computed and the threshold with the smallest RMSE is selected.

Here, only density-based sparsification and trimming is shown for the clustering coefficient.
```{r, echo=F, message=F, warning=F}
data.bRMSE.full <- data.gvars  %>%
  group_by(SparsMethod, ThreshMethod,Thresh) %>%
  mutate("Yhat"=lm(Y~Value, na.action = "na.exclude")$fitted) %>%
  mutate(RMSE=calc_rmse(Y, Yhat),
         R2=calc_rsq(Y,Yhat),
         CS=calc_cs(Y,Yhat)) 

data.bRMSE <- data.bRMSE.full %>%
  dplyr::select(SparsMethod, ThreshMethod, Thresh, RMSE, CS, R2) %>% 
  distinct(Thresh, .keep_all = TRUE)
```


<br>

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=8, fig.height=5, fig.cap="RMSE  for each of the models using the graph-theoretical features obtained afer sparsification using a certain threshold."}
data.bRMSE %>%
  ggplot(aes(x=Thresh, y=RMSE)) +
  geom_line() +
  theme_bw() +
  facet_grid(SparsMethod~ThreshMethod) +
  geom_vline(data = data.frame(xint=thr.grid,SparsMethod="weight-based", ThreshMethod="trim"), 
             aes(xintercept = xint), linetype = "dashed", col="red3")
```

```{r, echo=F, message=F, warning=F}
data.bRMSE.full %>%
  group_by(ID, SparsMethod, ThreshMethod) %>%
  slice_min(RMSE) %>%
  ggplot(aes(x=Y, y=Yhat))+
  geom_point(shape=1) + 
  geom_abline(intercept = 0, col="red3") +
  theme_bw()+
  facet_grid(SparsMethod~ThreshMethod)
```

<br>

```{r}
data.bRMSE %>%
  group_by(SparsMethod, ThreshMethod) %>%
  slice_min(RMSE, with_ties = F) %>%
  mutate_at(4:6, round_0, digits=3) %>%
  arrange(RMSE) %>%
  kbl(caption="Performance of the best RMSE approach", escape = F) %>%
  row_spec(0, bold=T) %>%
  kable_classic(full_width = T, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
  
```


## Average across sequence
```{r}
# ------ Average feature across threshold sequence
data.AVG.full <- data.gvars %>%
  group_by(SparsMethod, ThreshMethod, ID, Y) %>%
  summarise("Value.avg"=mean(Value, na.rm=T)) %>%
  group_by(SparsMethod, ThreshMethod) %>%
  mutate("Yhat"=lm(Y~Value.avg, na.action = "na.exclude")$fitted) 

data.AVG <- data.AVG.full %>%
  summarise("RMSE"=calc_rmse(Y,Yhat), "R2"=calc_rsq(Y,Yhat), "CS"=calc_cs(Y,Yhat))
```


```{r, echo=F, message=F, warning=F}
data.AVG.full %>%
  group_by(ID, SparsMethod, ThreshMethod) %>%
  ggplot(aes(x=Y, y=Yhat))+
  geom_point(shape=1) + 
  geom_abline(intercept = 0, col="red3") +
  theme_bw()+
  facet_grid(SparsMethod~ThreshMethod)
```

<br>

```{r}
data.AVG %>%
  mutate_at(3:5, round_0, digits=3) %>%
  arrange(RMSE) %>%
  kbl(caption="Performance of the averaging across the sequence approach", escape = F) %>%
  row_spec(0, bold=T) %>%
  kable_classic(full_width = T, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```



# Results

```{r}
data.AVG <- data.AVG %>%
  mutate(Thresh =NA,
         Method= "AVG")
data.bRMSE <- data.bRMSE %>%
  group_by(SparsMethod, ThreshMethod) %>%
  slice_min(RMSE, with_ties = F) %>%
  mutate(Method="bRMSE")
data.FDA$Method <- "FDA"
data.perf <- rbind(data.AVG, data.bRMSE, data.FDA) %>%
  data.frame() %>%
  relocate(Method, .before=SparsMethod) %>%
  relocate(Thresh, .before=RMSE) %>%
  arrange(RMSE)

data.perf %>%
  mutate_at(5:7, round_0, digits=4) %>%
  arrange(RMSE) %>%
  kbl(caption="Performance of all analysis approaches", escape = F) %>%
  row_spec(0, bold=T) %>%
  kable_classic(full_width = T, html_font = "Calibri")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T, position = "left",fixed_thead = T)
```


# References

<div id="refs"></div>
